# Massive Parallel RAG Pipeline

Demonstrates Flow4AI's parallel execution at scale with 1000+ document chunks.

## Technical Decisions

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Vector DB** | ChromaDB | Pure Python, persistent, no external DB needed |
| **Ordinary DB** | None | ChromaDB handles persistence (stores to disk) |
| **Embedding Model** | OpenAI `text-embedding-3-small` | Fast, cheap, 1536 dimensions |
| **Generation Model** | OpenAI `gpt-4o-mini` | Cost-effective, good quality |
| **Reranking** | BM25 via `rank-bm25` | Lightweight, pure Python, no GPU |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INDEXING PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Download Books â†’ Chunk Text â†’ Parallel Embed â†’ Store in Chroma â”‚
â”‚       (1)            (N)       (N parallel)        (batch)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        QUERY PIPELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Query â†’ Embed â†’ Vector Search â†’ BM25 Rerank â†’ Generate Answer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dependencies

```bash
pip install chromadb rank-bm25
# OpenAI API key required
export OPENAI_API_KEY=your_key_here
```

## Usage

```bash
# Full pipeline (index + query)
python rag_pipeline.py

# Index only (with chunk limit for testing)
python rag_pipeline.py --mode index --chunks 100

# Query only (uses existing index)
python rag_pipeline.py --mode query --query "What is Alice's adventure?"

# Specific books
python rag_pipeline.py --books alice_wonderland sherlock_holmes
```

## Flow4AI Pattern

The key demonstration is **parallel embedding** with Flow4AI:

```python
# Submit 1000+ embedding tasks concurrently
workflow = job(embed=embed_chunk)
fm = FlowManager(on_complete=on_complete)
fq_name = fm.add_workflow(workflow, "embedding_pipeline")

for chunk in chunks:
    task = {"embed.chunk_id": chunk.id, "embed.text": chunk.text}
    fm.submit_task(task, fq_name)

fm.wait_for_completion(timeout=300)
```

## Scale Testing Results

| Chunks | Status |
|--------|--------|
| 1 | âœ… Tested (1.54s, 0.6 chunks/sec) |
| 10 | ğŸ”„ In progress |
| 100 | â³ Pending |
| 1000 | â³ Pending |

## Status

**Branch**: `feature/massive-parallel-rag`  
**Current State**: Work in progress - basic pipeline functional with 1 chunk

### Known Issues
- Need to investigate async/sync behavior with OpenAI embeddings
- Scale testing incomplete

### TODO
- [ ] Complete scale testing (10, 100, 1000 chunks)
- [ ] Needle-in-haystack tests
- [ ] Edge case testing
